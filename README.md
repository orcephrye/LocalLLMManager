# Local LLM Manager

Yet another Local LLM Manager. This searches HuggingFace for GGUF/LLama.cpp compatible models. 

It makes it easy to download models and load multiple models at the same time and 
route models through a simple OpenAI API proxy. This means you can use a tool like 
OpenWeb UI to access a single endpoint. 